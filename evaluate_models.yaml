name: Evaluate models
inputs:
- {name: test_data_path, type: String}
- {name: lin_model_path, type: String}
- {name: rf_model_path, type: String}
- {name: xgb_model_path, type: String}
- {name: bucket, type: String}
- {name: bucket_name, type: String}
- {name: scores_path, type: String}
outputs:
- {name: Output, type: JsonArray}
implementation:
  container:
    image: python:3.7
    command:
    - sh
    - -c
    - (PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'pandas' 'xgboost' 'scikit-learn' 'fsspec' 'gcsfs' 'google-cloud-storage' ||
      PIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet --no-warn-script-location
      'pandas' 'xgboost' 'scikit-learn' 'fsspec' 'gcsfs' 'google-cloud-storage' --user)
      && "$0" "$@"
    - python3
    - -u
    - -c
    - "def evaluate_models(test_data_path, lin_model_path, rf_model_path, xgb_model_path,\
      \ bucket, bucket_name, scores_path):\n\n    import pandas as pd\n    import\
      \ numpy as np\n    from google.cloud import storage  \n    from sklearn.model_selection\
      \ import train_test_split, ShuffleSplit, GridSearchCV, StratifiedKFold\n   \
      \ import _pickle as cPickle\n    from io import BytesIO\n    from sklearn import\
      \ metrics\n    import xgboost\n\n    #load unseen test data\n    test_df = pd.read_csv(bucket\
      \ + test_data_path)\n    x_test =  test_df.drop('price', axis=1)\n    y_test\
      \ =  test_df['price']\n\n    model_paths = [lin_model_path, rf_model_path, xgb_model_path]\n\
      \n    #iterate over models, load and score each one, keep the best\n    scores\
      \ =[]\n    for path in model_paths:    \n        client = storage.Client()\n\
      \        my_bucket = client.get_bucket(bucket_name)\n        blob = my_bucket.get_blob(path)\n\
      \        if blob is None:\n            raise AttributeError('No files to download')\
      \ \n        model_bytestream = BytesIO(blob.download_as_string())\n        model\
      \ = cPickle.load(model_bytestream)\n        y_pred = model.predict(x_test)\n\
      \        score = metrics.mean_absolute_error(y_test, y_pred)\n        print(score)\n\
      \        scores.append({'model': path, 'score': score})\n\n    scores_df = pd.DataFrame(scores)\n\
      \    scores_df.to_csv(bucket + scores_path, index=False)\n    return scores\n\
      \ndef _serialize_json(obj) -> str:\n    if isinstance(obj, str):\n        return\
      \ obj\n    import json\n    def default_serializer(obj):\n        if hasattr(obj,\
      \ 'to_struct'):\n            return obj.to_struct()\n        else:\n       \
      \     raise TypeError(\"Object of type '%s' is not JSON serializable and does\
      \ not have .to_struct() method.\" % obj.__class__.__name__)\n    return json.dumps(obj,\
      \ default=default_serializer, sort_keys=True)\n\nimport argparse\n_parser =\
      \ argparse.ArgumentParser(prog='Evaluate models', description='')\n_parser.add_argument(\"\
      --test-data-path\", dest=\"test_data_path\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--lin-model-path\", dest=\"lin_model_path\", type=str,\
      \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--rf-model-path\"\
      , dest=\"rf_model_path\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--xgb-model-path\", dest=\"xgb_model_path\", type=str,\
      \ required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"--bucket\"\
      , dest=\"bucket\", type=str, required=True, default=argparse.SUPPRESS)\n_parser.add_argument(\"\
      --bucket-name\", dest=\"bucket_name\", type=str, required=True, default=argparse.SUPPRESS)\n\
      _parser.add_argument(\"--scores-path\", dest=\"scores_path\", type=str, required=True,\
      \ default=argparse.SUPPRESS)\n_parser.add_argument(\"----output-paths\", dest=\"\
      _output_paths\", type=str, nargs=1)\n_parsed_args = vars(_parser.parse_args())\n\
      _output_files = _parsed_args.pop(\"_output_paths\", [])\n\n_outputs = evaluate_models(**_parsed_args)\n\
      \n_outputs = [_outputs]\n\n_output_serializers = [\n    _serialize_json,\n\n\
      ]\n\nimport os\nfor idx, output_file in enumerate(_output_files):\n    try:\n\
      \        os.makedirs(os.path.dirname(output_file))\n    except OSError:\n  \
      \      pass\n    with open(output_file, 'w') as f:\n        f.write(_output_serializers[idx](_outputs[idx]))\n"
    args:
    - --test-data-path
    - {inputValue: test_data_path}
    - --lin-model-path
    - {inputValue: lin_model_path}
    - --rf-model-path
    - {inputValue: rf_model_path}
    - --xgb-model-path
    - {inputValue: xgb_model_path}
    - --bucket
    - {inputValue: bucket}
    - --bucket-name
    - {inputValue: bucket_name}
    - --scores-path
    - {inputValue: scores_path}
    - '----output-paths'
    - {outputPath: Output}
