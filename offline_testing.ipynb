{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preprocessing(raw_data_path, prep_data_path, bucket):\n",
    "\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.preprocessing import LabelEncoder, StandardScaler,OneHotEncoder\n",
    "    from sklearn.pipeline import make_pipeline,Pipeline\n",
    "    from sklearn.compose import make_column_transformer\n",
    "    from google.cloud import storage    \n",
    "    from io import BytesIO\n",
    "\n",
    "    # client = storage.Client()\n",
    "    # file_name = raw_data\n",
    "    # bucket = client.get_bucket(bucket_name)\n",
    "    # blob = bucket.get_blob(raw_data)\n",
    "    # content = blob.download_as_string()\n",
    "    #df = pd.read_csv(BytesIO(content))\n",
    "    df = pd.read_csv(bucket + raw_data_path)\n",
    "\n",
    "\n",
    "    #deleting unwanted columns\n",
    "    drop_columns = ['id','url', 'region', 'region_url','model','title_status', 'title_status','county', 'vin', 'description','size', 'image_url', 'lat','long','state','paint_color','cylinders']\n",
    "    df = df.drop(columns=drop_columns)\n",
    "    #deleting rows with nan values\n",
    "    df = df.dropna()\n",
    "    #reformatting/cleaning numeric columns\n",
    "    df['price'] = df['price'].astype(int)\n",
    "    df['year'] = df['year'].astype(int)\n",
    "    df['odometer'] = df['odometer'].astype(int)\n",
    "    df['odometer'] = df['odometer'] // 5000\n",
    "    df = df[df['year'] > 110]\n",
    "    df = df[(df['price']>1000) & (df['price']<50000)]\n",
    "\n",
    "    #reformatting/cleaning categorical columns\n",
    "    df['manufacturer'] = df['manufacturer'].astype(str)\n",
    "    df['condition'] = df['condition'].astype(str)\n",
    "    # df['cylinders'] = df['cylinders'].astype(str)\n",
    "    df['fuel'] = df['fuel'].astype(str)\n",
    "    df['transmission'] = df['transmission'].astype(str)\n",
    "    df['drive'] = df['drive'].astype(str)\n",
    "    df['type'] = df['type'].astype(str)\n",
    "    df=df[df['transmission']!='other']\n",
    "    df=df.reset_index()\n",
    "    \n",
    "    #print(df['transmission'].value_counts())\n",
    "\n",
    "    #label encode columns\n",
    "\n",
    "    lab_cat_columns=['transmission']\n",
    "\n",
    "#     for col in lab_cat_columns:\n",
    "#         if col in df.columns:\n",
    "#             le = LabelEncoder()\n",
    "#             le.fit(list(df[col].astype(str).values))\n",
    "#             df[col] = le.transform(list(df[col].astype(str).values))\n",
    "\n",
    "    conditions = {'salvage': 0, 'fair': 1, 'good': 2, 'excellent': 3, 'like new': 4, 'new': 5}\n",
    "    df['condition'].replace(conditions, inplace=True)\n",
    "    \n",
    "    transmissions={'automatic': 1, 'manual': 0}\n",
    "    df['transmission'].replace(transmissions, inplace=True)      \n",
    "    #Creating pipeline\n",
    "\n",
    "    numerical_features=['year', 'odometer']\n",
    "    one_hot_cat_columns=['manufacturer','fuel','drive','type']\n",
    "\n",
    "\n",
    "    categoric_transformer = make_pipeline(OneHotEncoder(sparse=False,handle_unknown='ignore'))\n",
    "\n",
    "    # Creating a pipeline with mean imputer for numerical data \n",
    "    numeric_transformer =  make_pipeline(StandardScaler())  \n",
    "\n",
    "    #Creating label transformer\n",
    "\n",
    "    # label_transformer=make_pipeline(LabelEncoder())\n",
    "\n",
    "    # Combining both pipelines such that each pipeline works on the columns it was meant for\n",
    "    preprocessor = make_column_transformer((categoric_transformer,one_hot_cat_columns),\n",
    "                                            (numeric_transformer,numerical_features))\n",
    "    #                                           (label_transformer,lab_cat_columns))\n",
    "\n",
    "    pipe=Pipeline(steps = [('prep',preprocessor)])\n",
    "    results=pipe.fit_transform(df)\n",
    "    results=pd.DataFrame(data=results, columns=list(pd.get_dummies(df[one_hot_cat_columns]).columns)+numerical_features )\n",
    "\n",
    "    final_df=results\n",
    "    # final_df['year']=df['year']\n",
    "    # final_df['odometer']=df['odometer']\n",
    "    final_df['condition']=df['condition']\n",
    "    final_df['transmission']=df['transmission']\n",
    "    final_df['price']=df['price']\n",
    "    \n",
    "    columns_series = pd.Series(final_df.columns, dtype='string', name='train_df_columns')\n",
    "    columns_series.to_csv(bucket + '/data/train_columns.csv', index=False)\n",
    "\n",
    "#     final_df.to_csv(bucket + prep_data_path)\n",
    "#     return prep_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessing('/data/raw_vehicles.csv', '/data/prep_vehicles.csv', 'gs://de-3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_model_training(prep_data_path, bucket, bucket_name, model_path):\n",
    "    \n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from google.cloud import storage  \n",
    "    from sklearn.model_selection import train_test_split, ShuffleSplit, GridSearchCV, StratifiedKFold\n",
    "    import _pickle as cPickle \n",
    "    from sklearn import metrics\n",
    "    from sklearn.ensemble import RandomForestRegressor  \n",
    "    from urllib.parse import urlparse\n",
    "\n",
    "    df = pd.read_csv(bucket + prep_data_path)\n",
    "\n",
    "    #Seperating dataset and target variable\n",
    "    target_name = 'price'\n",
    "    df_target = df[target_name]\n",
    "    df = df.drop([target_name], axis=1)\n",
    "    #Train test split\n",
    "    train, test, target, target_test = train_test_split(df, df_target, test_size=0.2, random_state=0)\n",
    "    #return [train, test, target, target_test]\n",
    "\n",
    "    #read preprocessed data\n",
    "    #train, test, target, target_test = _read_and_split_data(prep_data_path, bucket)\n",
    "    #Tuning RF Parameters\n",
    "    rf_param_grid = {'n_estimators': [100,500],\n",
    "                'max_features': [0.2,0.7]\n",
    "                }\n",
    "    rf_GS = GridSearchCV(RandomForestRegressor(n_jobs=-1), param_grid=rf_param_grid,\n",
    "                    cv=ShuffleSplit(n_splits=3,random_state=1), verbose=False, pre_dispatch='2*n_jobs')\n",
    "\n",
    "    rf_GS.fit(train, target)\n",
    "\n",
    "\n",
    "    score=rf_GS.score(train, target)\n",
    "    y_pred=rf_GS.predict(test)\n",
    "    #print('R^2 on the train set', score)\n",
    "    print('R2 score', metrics.r2_score(target_test, y_pred))\n",
    "\n",
    "    temp_model_path='/tmp/rf_model.pickle'\n",
    "    with open(temp_model_path, 'wb') as f:\n",
    "        cPickle.dump(rf_GS, f, -1)\n",
    "    \n",
    "    parse = urlparse(url=bucket+model_path, allow_fragments=False)\n",
    "    print(parse.path)\n",
    "    print(parse.netloc)\n",
    "    \n",
    "    if parse.path[0] =='/':\n",
    "        parsed_model_path = parse.path[1:]\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket(parse.netloc)\n",
    "    model = bucket.blob(parsed_model_path)\n",
    "    model.upload_from_filename(temp_model_path)\n",
    "    return model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score 0.7816622118347524\n",
      "/models/rf_model.pickle\n",
      "de-3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/models/rf_model.pickle'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model_training('/data/prep_vehicles.csv', 'gs://de-3','de-3', '/models/rf_model.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_best_model():\n",
    "#     best_model_file = open(r\"/best_model.txt\",\"w+\")\n",
    "#     best_model_file.write('models/xgb_model.pickle')\n",
    "#     best_model_file.close()\n",
    "    import _pickle as cPickle\n",
    "    from google.cloud import storage  \n",
    "    path = 'models/xgb_model.pickle'\n",
    "    temp_model_path='/tmp/best_model.pickle'\n",
    "    with open(temp_model_path, 'wb') as f:\n",
    "        cPickle.dump(path, f, -1)\n",
    "        \n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket('de-3')\n",
    "    model = bucket.blob('')\n",
    "    model.upload_from_filename(temp_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_best_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "car_dicts = [{'manufacturer': 'bmw', 'fuel': 'gas', 'drive': 'rwd', 'type':'coupe', \n",
    "              'transmission':'automatic', 'condition':'new', 'year': 2010, 'odometer': 50000 }]\n",
    "\n",
    "df_cols = ['manufacturer_acura', 'manufacturer_audi', 'manufacturer_bmw',\n",
    "       'manufacturer_buick', 'manufacturer_cadillac', 'manufacturer_chevrolet',\n",
    "       'manufacturer_chrysler', 'manufacturer_dodge', 'manufacturer_fiat',\n",
    "       'manufacturer_ford', 'manufacturer_gmc', 'manufacturer_honda',\n",
    "       'manufacturer_hyundai', 'manufacturer_infiniti', 'manufacturer_jaguar',\n",
    "       'manufacturer_jeep', 'manufacturer_kia', 'manufacturer_lexus',\n",
    "       'manufacturer_lincoln', 'manufacturer_mazda',\n",
    "       'manufacturer_mercedes-benz', 'manufacturer_mercury',\n",
    "       'manufacturer_mini', 'manufacturer_mitsubishi', 'manufacturer_nissan',\n",
    "       'manufacturer_pontiac', 'manufacturer_ram', 'manufacturer_rover',\n",
    "       'manufacturer_saturn', 'manufacturer_subaru', 'manufacturer_tesla',\n",
    "       'manufacturer_toyota', 'manufacturer_volkswagen', 'manufacturer_volvo',\n",
    "       'fuel_diesel', 'fuel_electric', 'fuel_gas', 'fuel_hybrid', 'fuel_other',\n",
    "       'drive_4wd', 'drive_fwd', 'drive_rwd', 'type_SUV', 'type_bus',\n",
    "       'type_convertible', 'type_coupe', 'type_hatchback', 'type_mini-van',\n",
    "       'type_offroad', 'type_other', 'type_pickup', 'type_sedan', 'type_truck',\n",
    "       'type_van', 'type_wagon', 'year', 'odometer', 'condition',\n",
    "       'transmission']\n",
    "\n",
    "conditions = {'salvage': 0, 'fair': 1, 'good': 2, 'excellent': 3, 'like new': 4, 'new': 5}\n",
    "transmissions = {'manual': 0, 'automatic': 1}\n",
    "\n",
    "\n",
    "encoded_df = pd.DataFrame(columns=df_cols)\n",
    "\n",
    "for car in car_dicts:\n",
    "    new_row_dict = {}\n",
    "    for col in df_cols:\n",
    "        if 'manufacturer' in col:\n",
    "            if car['manufacturer'] in col:\n",
    "                new_row_dict[col]=1\n",
    "            else: \n",
    "                new_row_dict[col]=0\n",
    "        if 'fuel' in col:\n",
    "            if car['fuel'] in col:\n",
    "                new_row_dict[col]=1\n",
    "            else: \n",
    "                new_row_dict[col]=0                \n",
    "        elif 'drive' in col:\n",
    "            if car['drive'] in col:\n",
    "                new_row_dict[col]=1\n",
    "            else: \n",
    "                new_row_dict[col]=0        \n",
    "        elif 'type' in col:\n",
    "            if car['type'] in col:\n",
    "                new_row_dict[col]=1\n",
    "            else: \n",
    "                new_row_dict[col]=0        \n",
    "        elif col=='condition':\n",
    "            new_row_dict['condition']= conditions[car['condition']]        \n",
    "        elif col=='transmission':\n",
    "            new_row_dict['transmission']= transmissions[car['transmission']]\n",
    "        elif col=='year': \n",
    "            new_row_dict[col]= car[col]\n",
    "        elif col=='odometer': \n",
    "            new_row_dict[col]= car[col]\n",
    "    #print (len(new_row_dict.keys()))\n",
    "    encoded_df = encoded_df.append(new_row_dict, ignore_index=True)\n",
    "encoded_df = encoded_df.astype('float64')   \n",
    "min_odometer = encoded_df['odometer'].idxmin()\n",
    "print(encoded_df['year'][min_odometer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      " * Restarting with inotify reloader\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from flask import Flask, json, request, Response\n",
    "import _pickle as cPickle\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler,OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "#from resources import predictor\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.config[\"DEBUG\"] = True\n",
    "\n",
    "def preprocess(new_cars): \n",
    "    #label encode columns\n",
    "\n",
    "    df_cols = ['manufacturer_acura', 'manufacturer_audi', 'manufacturer_bmw',\n",
    "        'manufacturer_buick', 'manufacturer_cadillac', 'manufacturer_chevrolet',\n",
    "        'manufacturer_chrysler', 'manufacturer_dodge', 'manufacturer_fiat',\n",
    "        'manufacturer_ford', 'manufacturer_gmc', 'manufacturer_honda',\n",
    "        'manufacturer_hyundai', 'manufacturer_infiniti', 'manufacturer_jaguar',\n",
    "        'manufacturer_jeep', 'manufacturer_kia', 'manufacturer_lexus',\n",
    "        'manufacturer_lincoln', 'manufacturer_mazda',\n",
    "        'manufacturer_mercedes-benz', 'manufacturer_mercury',\n",
    "        'manufacturer_mini', 'manufacturer_mitsubishi', 'manufacturer_nissan',\n",
    "        'manufacturer_pontiac', 'manufacturer_ram', 'manufacturer_rover',\n",
    "        'manufacturer_saturn', 'manufacturer_subaru', 'manufacturer_tesla',\n",
    "        'manufacturer_toyota', 'manufacturer_volkswagen', 'manufacturer_volvo',\n",
    "        'fuel_diesel', 'fuel_electric', 'fuel_gas', 'fuel_hybrid', 'fuel_other',\n",
    "        'drive_4wd', 'drive_fwd', 'drive_rwd', 'type_SUV', 'type_bus',\n",
    "        'type_convertible', 'type_coupe', 'type_hatchback', 'type_mini-van',\n",
    "        'type_offroad', 'type_other', 'type_pickup', 'type_sedan', 'type_truck',\n",
    "        'type_van', 'type_wagon', 'year', 'odometer', 'condition',\n",
    "        'transmission']\n",
    "\n",
    "    conditions = {'salvage': 0, 'fair': 1, 'good': 2, 'excellent': 3, 'like new': 4, 'new': 5}\n",
    "    transmissions = {'manual': 0, 'automatic': 1}\n",
    "\n",
    "\n",
    "    encoded_df = pd.DataFrame(columns=df_cols)\n",
    "\n",
    "    for car in new_cars:\n",
    "        new_row_dict = {}\n",
    "        for col in df_cols:\n",
    "            if 'manufacturer' in col:\n",
    "                if car['manufacturer'] in col:\n",
    "                    new_row_dict[col]=1\n",
    "                else: \n",
    "                    new_row_dict[col]=0\n",
    "            if 'fuel' in col:\n",
    "                if car['fuel'] in col:\n",
    "                    new_row_dict[col]=1\n",
    "                else: \n",
    "                    new_row_dict[col]=0                \n",
    "            elif 'drive' in col:\n",
    "                if car['drive'] in col:\n",
    "                    new_row_dict[col]=1\n",
    "                else: \n",
    "                    new_row_dict[col]=0        \n",
    "            elif 'type' in col:\n",
    "                if car['type'] in col:\n",
    "                    new_row_dict[col]=1\n",
    "                else: \n",
    "                    new_row_dict[col]=0        \n",
    "            elif col=='condition':\n",
    "                new_row_dict['condition']= conditions[car['condition']]        \n",
    "            elif col=='transmission':\n",
    "                new_row_dict['transmission']= transmissions[car['transmission']]\n",
    "            elif col=='year': \n",
    "                new_row_dict[col]= car[col]\n",
    "            elif col=='odometer': \n",
    "                new_row_dict[col]= car[col]\n",
    "        #print (new_row_dict)\n",
    "        encoded_df = encoded_df.append(new_row_dict, ignore_index=True)\n",
    "        \n",
    "    encoded_df = encoded_df.astype('float64')\n",
    "    min_odometer = encoded_df['odometer'].idxmin()\n",
    "    print(encoded_df['score'][min_odometer])\n",
    "    return encoded_df\n",
    "\n",
    "\n",
    "@app.route('/price-predict', methods=['POST'])\n",
    "def predict_perf():\n",
    "    content = request.get_json()\n",
    "    #print(content)\n",
    "\n",
    "    #test_df = pd.read_json(json.dumps(content), orient='records')\n",
    "\n",
    "    js_str_ = json.dumps(content)\n",
    "    dicts = json.loads(js_str)\n",
    "    #print(type(dict_[0]['sepal_length']))\n",
    "\n",
    "    prep_cars = preprocess(dicts)\n",
    "\n",
    "    client = storage.Client()\n",
    "    bucket = client.get_bucket('de-3')\n",
    "    blob = bucket.get_blob('models/xgb_model.pickle')\n",
    "    if blob is None:\n",
    "        raise AttributeError('No files to download') \n",
    "    model_bytestream = BytesIO(blob.download_as_string())\n",
    "    model = cPickle.load(model_bytestream)\n",
    "\n",
    "    result = model.predict(prep_cars)\n",
    "    js_result=json.dumps(result.to_dict(orient='records'), indent=4, sort_keys=False)\n",
    "\n",
    "    resp = Response(js_result, status=200, mimetype='application/json')\n",
    "    resp.headers['Access-Control-Allow-Origin'] = '*'\n",
    "    resp.headers['Access-Control-Allow-Methods'] = 'POST'\n",
    "    resp.headers['Access-Control-Max-Age'] = '1000'\n",
    "    return resp\n",
    "    \n",
    "\n",
    "\n",
    "app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cpu.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
